â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ†  ENDURANCE LAB AI â€” Asistente Virtual Deportivo
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ Asistente especializado en entrenamiento de resistencia:  
   ciclismo Â· running Â· triatlÃ³n Â· nataciÃ³n

ğŸ“Œ Proyecto Final de los cursos:
   â€¢ Procesamiento de Lenguaje Natural  
   â€¢ Experiencias en Inteligencia de Negocios  

ğŸ‘¤ Autor: Juan Felipe Cardona Arango  
ğŸ“… Fecha: Mayo 2025  
ğŸ‘¨â€ğŸ« Docentes:  
   â€¢ Juan David MartÃ­nez Vargas  
   â€¢ Ana MarÃ­a LÃ³pez Moreno  
   â€¢ Edwin Nelson Montoya MÃºnera  

-------------------------------------------------------
ğŸ“– DESCRIPCIÃ“N GENERAL
-------------------------------------------------------

Este repositorio contiene el desarrollo completo del asistente **Endurance Lab AI**:
âœ” PersonalizaciÃ³n del dominio y prompts  
âœ” EvaluaciÃ³n automÃ¡tica con LangChain + MLflow  
âœ” Dataset de pruebas y anÃ¡lisis  
âœ” Dashboard interactivo  
âœ” Reflexiones finales y criterio de claridad para usuarios deportistas

-------------------------------------------------------
ğŸ—‚ï¸ ESTRUCTURA DEL CONTENIDO
-------------------------------------------------------

1. â–¶ Parte 1: PersonalizaciÃ³n
2. â–¶ Parte 2: EvaluaciÃ³n AutomÃ¡tica
3. â–¶ Parte 3: Reto Investigador
4. â–¶ Parte 4: Dashboard de MÃ©tricas
5. â–¶ Parte 5: PresentaciÃ³n y ReflexiÃ³n
6. â–¶ BONUS: EvaluaciÃ³n de Claridad
7. â–¶ CÃ³mo Ejecutar el Proyecto
8. â–¶ Licencia

-------------------------------------------------------
ğŸ“ PARTE 1: PERSONALIZACIÃ“N
-------------------------------------------------------

ğŸ”¹ Dominio TemÃ¡tico:
   â€¢ Entrenamiento deportivo de resistencia
   â€¢ Foco en ciclismo, triatlÃ³n, nataciÃ³n y running

ğŸ”¹ Documentos Internos Sustituidos:
   â€¢ planes_entrenamiento.pdf
   â€¢ historiales_rendimiento.pdf
   â€¢ guias_nutricion.pdf
   â€¢ revisiones_bibliograficas.pdf

ğŸ”¹ Prompts:
   â–« Principal â†’ Respuestas completas, con validaciÃ³n de contexto y cita textual
   â–« Secundario â†’ Respuestas breves y directas, solo si hay contexto suficiente

ğŸ”¹ Dataset de Pruebas:
   â€¢ Archivo: eval_dataset.csv  
   â€¢ Incluye casos reales y extremos

-------------------------------------------------------
ğŸ¤– PARTE 2: EVALUACIÃ“N AUTOMÃTICA
-------------------------------------------------------

âš™ Script principal: run_eval.py  
ğŸ§  Framework: LangChain  
ğŸ“Š Seguimiento: MLflow

Criterios evaluados automÃ¡ticamente:
â€¢ Correctness  
â€¢ Relevance  
â€¢ Coherence  
â€¢ Toxicity  
â€¢ Harmfulness

-------------------------------------------------------
ğŸ”¬ PARTE 3: RETO INVESTIGADOR
-------------------------------------------------------

Se aÃ±adieron criterios avanzados personalizados:
â€¢ *_score â†’ MÃ©trica numÃ©rica  
â€¢ *_reasoning â†’ ExplicaciÃ³n textual

-------------------------------------------------------
ğŸ“Š PARTE 4: DASHBOARD DE MÃ‰TRICAS
-------------------------------------------------------

ğŸ—‚ Archivos clave:
   â€¢ dashboard.py â†’ GrÃ¡ficas por criterio  
   â€¢ app/main_interface.py â†’ Interfaz visual y filtros

-------------------------------------------------------
ğŸ“ˆ PARTE 5: PRESENTACIÃ“N Y REFLEXIÃ“N
-------------------------------------------------------

EvaluaciÃ³n comparativa:

 ConfiguraciÃ³n            | Correct | Relevant | Coherent | Toxic | Harmful
 -------------------------|---------|----------|----------|-------|---------
 Chunk = 512 Â· Prompt A   |  0.87   |   0.85   |   0.82   | 0.00  |  0.00
 Chunk = 256 Â· Prompt B   |  0.92   |   0.90   |   0.88   | 0.00  |  0.00

âœ… Mejor combinaciÃ³n: Chunk 256 + Prompt B  
âš ï¸ Hallazgos: Incoherencia leve y formato inconsistente en chunks largos

-------------------------------------------------------
âœ¨ BONUS: CRITERIO DE CLARIDAD
-------------------------------------------------------

EvalÃºa si la respuesta es comprensible para un deportista (fluidez, jerga, estructura).  
Resultados guardados como:  
â€¢ clarity_score (valor numÃ©rico)  
â€¢ clarity_reasoning (explicaciÃ³n registrada en MLflow)

-------------------------------------------------------
ğŸ› ï¸ CÃ“MO EJECUTAR EL PROYECTO
-------------------------------------------------------

1ï¸âƒ£ Instalar dependencias:
   pip install -r requirements.txt

2ï¸âƒ£ Ejecutar la evaluaciÃ³n automÃ¡tica:
   python run_eval.py --dataset eval_dataset.csv

3ï¸âƒ£ Lanzar la aplicaciÃ³n Streamlit:
   streamlit run app/main_interface.py

ğŸŒ Luego, accede en tu navegador a:
   http://localhost:8501

-------------------------------------------------------
ğŸ“„ LICENCIA
-------------------------------------------------------

Este proyecto estÃ¡ licenciado bajo los tÃ©rminos de la Licencia MIT.  
Revisa el archivo LICENSE para mÃ¡s informaciÃ³n.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

