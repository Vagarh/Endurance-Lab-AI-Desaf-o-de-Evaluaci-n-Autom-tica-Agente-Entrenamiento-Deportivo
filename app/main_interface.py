# app/main_interface.py
"""
Enduranceâ€¯Labâ€¯AI Â· Streamlit frontâ€‘end
Author  : Juanâ€¯Felipeâ€¯Cardonaâ€¯Arango  (github.com/Vagarh)
Repo    : https://github.com/Vagarh/Endurance-Lab-AI-Desaf-o-de-Evaluaci-n-Autom-tica-Agente-Entrenamiento-Deportivo
License : MIT
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Imports
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import sys, os, traceback
from pathlib import Path
from datetime import datetime

import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import mlflow

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Rutas internas
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
APP_ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(APP_ROOT))  # para importar app.*

from app.rag_pipeline import load_vectorstore_from_disk, build_chain  # noqa: E402

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Constantes de branding
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REPO_URL      = "https://github.com/Vagarh/Endurance-Lab-AI-Desaf-o-de-Evaluaci-n-Autom-tica-Agente-Entrenamiento-Deportivo"
LOGO_URL      = "/Users/juanfelipearango/Desktop/chatbot-genaiops/Imagenes/ChatGPT Image 2 may 2025, 17_42_01.png"  # ajusta si cambias la ruta
HERO_URL      = "/Users/juanfelipearango/Desktop/chatbot-genaiops/Imagenes/ChatGPT Image 2 may 2025, 17_45_41.png"
APP_VERSION   = "1.0.0"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ConfiguraciÃ³n general
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Enduranceâ€¯Labâ€¯AI Â· Chatbot & MÃ©tricas",
    layout="wide",
    page_icon="ğŸ†",
    menu_items={
        "Get Help": REPO_URL,
        "Report a bug": REPO_URL + "/issues",
        "About": "Creado por Juanâ€¯Felipeâ€¯Cardonaâ€¯Arango Â· Â© {}".format(datetime.now().year),
    },
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  CSS global (burbujas + tipografÃ­a)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
    """
    <style>
      @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap');
      html, body, [class*="css"]  { font-family: 'Inter', sans-serif; }
      .bubble-user{
        background:#e8f4fd;
        padding:.65em;
        border-radius:.6em;
        margin-bottom:.5em;
      }
      .bubble-bot{
        background:#f6f8fa;
        padding:.65em;
        border-radius:.6em;
        margin-bottom:1em;
      }
      footer {visibility:hidden;} /* ocultar footer default */
    </style>
    """,
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Encabezado principal con hero
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
col_logo, col_title = st.columns([1, 6])
with col_logo:
    st.image(LOGO_URL, width=110)
with col_title:
    st.subheader("Enduranceâ€¯Labâ€¯AI")
    st.caption("Tu asistente virtual para entrenamiento de resistencia Â· v{}".format(APP_VERSION))

st.image(HERO_URL, width=200)

st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Cache de recursos RAG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner="ğŸ”„ Cargando base de conocimientosâ€¦")
def get_vectordb_and_chain():
    vectordb = load_vectorstore_from_disk()
    chain    = build_chain(vectordb)
    return vectordb, chain

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Sidebar
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.image(LOGO_URL, width=90)
    st.markdown("### NavegaciÃ³n")
    modo = st.radio("", ["ğŸ¤– Chatbot", "ğŸ“Š MÃ©tricas"], index=0)

    if modo == "ğŸ¤– Chatbot":
        sport = st.selectbox(
            "Disciplina principal",
            ("Ciclismo", "Running", "TriatlÃ³n", "NataciÃ³n", "Otro"),
            index=0,
        )
        st.markdown("<small>Elige tu disciplina para adaptar las recomendaciones.</small>", unsafe_allow_html=True)
        st.markdown("---")

    st.markdown("#### Recursos")
    st.markdown(f"[Repositorio en GitHub]({REPO_URL})")
    st.markdown("[Reportarâ€¯incidencia]({}/issues)".format(REPO_URL))
    st.markdown("---")
    st.markdown("<small>Â© {} Juanâ€¯Felipeâ€¯Cardonaâ€¯Arango</small>".format(datetime.now().year), unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Cargar RAG una sola vez
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_, chain = get_vectordb_and_chain()

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                                   CHAT                                   â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if modo == "ğŸ¤– Chatbot":
    st.header("ğŸ—£ï¸Â Chat con tu Coach de Resistencia")

    pregunta = st.text_input("Formula tu pregunta (p.â€¯ej.â€¯â€˜Â¿CÃ³mo estructuro mi semana de carga antes de la carrera?â€™):")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history: list[tuple[str, str]] = []

    if pregunta:
        with st.spinner("Generando respuestaâ€¦"):
            try:
                result  = chain.invoke({"question": pregunta, "chat_history": st.session_state.chat_history, "sport": sport})
                answer  = result["answer"]
            except Exception:
                answer  = "âš ï¸ Lo siento, ocurriÃ³ un error:\n\n```{}```".format(traceback.format_exc(limit=2))
            st.session_state.chat_history.append((pregunta, answer))

    if st.session_state.chat_history:
        st.markdown("---")
        for q, a in reversed(st.session_state.chat_history):
            st.markdown(f'<div class="bubble-user"><strong>ğŸ§‘â€ğŸ’»Â TÃº:</strong><br/>{q}</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="bubble-bot"><strong>ğŸ¤–Â Coach:</strong><br/>{a}</div>', unsafe_allow_html=True)

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                                  MÃ‰TRICAS                                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
else:  # modo == "ğŸ“Š MÃ©tricas"
    st.header("ğŸ“ˆÂ Resultados de EvaluaciÃ³n del LLM")

    try:
        client      = mlflow.tracking.MlflowClient()
        experiments = [exp for exp in client.search_experiments() if exp.name.startswith("eval_")]
    except Exception as e:
        st.error(f"No se pudo conectar a MLflow: {e}")
        st.stop()

    if not experiments:
        st.warning("No se encontraron experimentos de evaluaciÃ³n.")
        st.stop()

    exp_names     = [exp.name for exp in experiments]
    selected_exp  = st.selectbox("Selecciona un experimento:", exp_names)

    experiment    = next(exp for exp in experiments if exp.name == selected_exp)
    runs          = client.search_runs(experiment_ids=[experiment.experiment_id], order_by=["start_time DESC"])

    if not runs:
        st.warning("No hay ejecuciones registradas.")
        st.stop()

    # â”€â”€ DataFrame con parÃ¡metros y mÃ©tricas
    data = [
        {
            "Pregunta"  : run.data.params.get("question"),
            "Prompt"    : run.data.params.get("prompt_version"),
            "Chunk Size": int(run.data.params.get("chunk_size", 0)),
            "PrecisiÃ³n" : run.data.metrics.get("lc_is_correct", np.nan),
        }
        for run in runs
    ]
    df = pd.DataFrame(data)
    st.dataframe(df, use_container_width=True)

    # â”€â”€ Agrupar y limpiar
    grouped = (
        df.groupby(["Prompt", "Chunk Size"], dropna=False)
          .agg({"PrecisiÃ³n": "mean"})
          .reset_index()
    )
    grouped["PrecisiÃ³n"] = pd.to_numeric(grouped["PrecisiÃ³n"], errors="coerce")
    grouped = grouped.dropna(subset=["PrecisiÃ³n"])
    grouped = grouped[grouped["PrecisiÃ³n"].apply(np.isfinite)]

    if grouped.empty:
        st.info("No hay datos suficientes para graficar la precisiÃ³n.")
    else:
        grouped["config"] = grouped["Prompt"] + " | " + grouped["Chunk Size"].astype(str)

        chart = (
            alt.Chart(grouped)
               .mark_bar()
               .encode(
                   x=alt.X("config:N", title="ConfiguraciÃ³n", sort=None),
                   y=alt.Y("PrecisiÃ³n:Q", title="PrecisiÃ³n media", scale=alt.Scale(domain=[0,1])),
                   tooltip=["Prompt", "Chunk Size", alt.Tooltip("PrecisiÃ³n:Q", format=".2f")],
               )
               .properties(width=640, height=420)
        )
        st.altair_chart(chart, use_container_width=True)

    st.markdown("---")
    st.markdown(
        "<small>GrÃ¡ficos generados con Altair â€¢ Datos almacenados y versionados con MLflow â€¢ CÃ³digo fuente en <a href='{}'>GitHub</a></small>".format(REPO_URL),
        unsafe_allow_html=True,
    )
