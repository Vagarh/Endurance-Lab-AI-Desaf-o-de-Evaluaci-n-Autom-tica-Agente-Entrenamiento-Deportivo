# app/main_interface.py
import sys, os, traceback
from pathlib import Path

import streamlit as st
import pandas as pd
import numpy as np            # â† NUEVO
import altair as alt          # â† NUEVO
import mlflow

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Rutas internas
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
APP_ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(APP_ROOT))           # para importar app.*

from app.rag_pipeline import load_vectorstore_from_disk, build_chain  # noqa: E402

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ConfiguraciÃ³n general
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Chatbot + MÃ©tricas Â· Endurance Coach",
    layout="wide",
    page_icon="ğŸ†",
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  CSS global (burbujas)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
    """
    <style>
      .bubble-user{
        background:#e8f4fd;
        color:#000;
        padding:0.6em;
        border-radius:.5em;
        margin-bottom:.5em;
      }
      .bubble-bot{
        background:#f6f8fa;
        color:#000;
        padding:0.6em;
        border-radius:.5em;
        margin-bottom:1em;
      }
    </style>
    """,
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Cache de recursos RAG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner="ğŸ”„ Cargando base de conocimientosâ€¦")
def get_vectordb_and_chain():
    vectordb = load_vectorstore_from_disk()
    chain = build_chain(vectordb)
    return vectordb, chain


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Sidebar
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
modo = st.sidebar.radio("ğŸ“‚ Selecciona una vista:", ["ğŸ¤– Chatbot", "ğŸ“Š MÃ©tricas"])

if modo == "ğŸ¤– Chatbot":
    sport = st.sidebar.selectbox(
        "Disciplina principal",
        ("Ciclismo", "Running", "TriatlÃ³n", "NataciÃ³n", "Otro"),
        index=0,
    )
    st.sidebar.markdown(
        "<small>Elige tu disciplina para adaptar las recomendaciones.</small>",
        unsafe_allow_html=True,
    )
    st.sidebar.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Cargar RAG una sola vez
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_, chain = get_vectordb_and_chain()

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                                   CHAT                                   â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if modo == "ğŸ¤– Chatbot":
    st.title("ğŸ†Â Asistente de Entrenamiento Deportivo")
    st.caption("PlanificaciÃ³n Â· AnÃ¡lisis de rendimiento Â· NutriciÃ³n")

    pregunta = st.text_input(
        "Formula tu pregunta (p.Â ej.Â Â«Â¿CÃ³mo estructuro mi semana de carga antes de la carrera?Â»):"
    )

    if "chat_history" not in st.session_state:
        st.session_state.chat_history: list[tuple[str, str]] = []

    if pregunta:
        with st.spinner("Generando respuestaâ€¦"):
            try:
                result = chain.invoke(
                    {
                        "question": pregunta,
                        "chat_history": st.session_state.chat_history,
                        "sport": sport,
                    }
                )
                answer = result["answer"]
            except Exception:
                answer = (
                    "âš ï¸ Lo siento, ocurriÃ³ un error al procesar tu pregunta.\n\n"
                    f"```{traceback.format_exc(limit=2)}```"
                )
            st.session_state.chat_history.append((pregunta, answer))

    if st.session_state.chat_history:
        st.markdown("---")
        for q, a in reversed(st.session_state.chat_history):
            st.markdown(
                f'<div class="bubble-user"><strong>ğŸ§‘â€ğŸ’»Â TÃº:</strong><br/>{q}</div>',
                unsafe_allow_html=True,
            )
            st.markdown(
                f'<div class="bubble-bot"><strong>ğŸ¤–Â Coach:</strong><br/>{a}</div>',
                unsafe_allow_html=True,
            )

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                                  MÃ‰TRICAS                                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
elif modo == "ğŸ“Š MÃ©tricas":
    st.title("ğŸ“ˆÂ Resultados de EvaluaciÃ³n del LLM")

    try:
        client = mlflow.tracking.MlflowClient()
        experiments = [
            exp for exp in client.search_experiments()
            if exp.name.startswith("eval_")
        ]
    except Exception as e:
        st.error(f"No se pudo conectar a MLflow: {e}")
        st.stop()

    if not experiments:
        st.warning("No se encontraron experimentos de evaluaciÃ³n.")
        st.stop()

    exp_names = [exp.name for exp in experiments]
    selected_exp = st.selectbox("Selecciona un experimento:", exp_names)

    experiment = next(exp for exp in experiments if exp.name == selected_exp)
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["start_time DESC"],
    )

    if not runs:
        st.warning("No hay ejecuciones registradas.")
        st.stop()

    # â”€â”€ DataFrame con parÃ¡metros y mÃ©tricas
    data = []
    for run in runs:
        params  = run.data.params
        metrics = run.data.metrics
        data.append(
            {
                "Pregunta":     params.get("question"),
                "Prompt":       params.get("prompt_version"),
                "Chunk Size":   int(params.get("chunk_size", 0)),
                "PrecisiÃ³n":    metrics.get("lc_is_correct", np.nan),
            }
        )

    df = pd.DataFrame(data)
    st.dataframe(df, use_container_width=True)

    # â”€â”€ Agrupar y limpiar
    grouped = (
        df.groupby(["Prompt", "Chunk Size"])
        .agg({"PrecisiÃ³n": "mean"})
        .reset_index()
    )

    # â”€â”€ ConversiÃ³n numÃ©rica y limpieza de NaN/Inf
    grouped["PrecisiÃ³n"] = pd.to_numeric(grouped["PrecisiÃ³n"], errors="coerce")
    grouped = grouped.dropna(subset=["PrecisiÃ³n"])
    grouped = grouped[grouped["PrecisiÃ³n"].apply(np.isfinite)]

    if grouped.empty:
        st.info("No hay datos suficientes para graficar la precisiÃ³n.")
    else:
        grouped["config"] = (
            grouped["Prompt"] + " | " + grouped["Chunk Size"].astype(str)
        )

        # â”€â”€ GrÃ¡fico robusto con Altair
        chart = (
            alt.Chart(grouped)
            .mark_bar()
            .encode(
                x=alt.X("config:N", title="ConfiguraciÃ³n", sort=None),
                y=alt.Y("PrecisiÃ³n:Q", title="PrecisiÃ³n media", scale=alt.Scale(domain=[0,1])),
                tooltip=["Prompt", "Chunk Size", alt.Tooltip("PrecisiÃ³n:Q", format=".2f")],
            )
            .properties(width=600, height=400)
        )
        st.altair_chart(chart, use_container_width=True)
